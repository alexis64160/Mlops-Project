# Mlops-Project

## 1. Quick start
### Premi√®re installation
- Cloner le repository, dans un dossier d√©di√©:
`git clone --depth=1 git@github.com:alexis64160/Mlops-Project.git .`

- Lancer le script prepare.sh
`./scripts/prepare.sh  `

- Configurer les fichiers .secrets et config.yaml:
`vim .secrets`
`vim config.yaml`

- Ex√©cuter le script install.sh:
`./scripts/install.sh`

- Lancer les services:
`./scripts/start.sh`

- Pour couper les services:
`./scripts/stop.sh`

- Pour r√©initialiser le d√©pot dans son √©tat d'oriigne:
ATTENTION: supprime toutes les donn√©es du projet
`./scripts/hard-reset.sh`

### Utilisation
Depuis Airflow, utiliser les diff√©rents dags.

## 2. Conventions:
- Les 4 lettres DSDC (pour DataScientest Document Classification) seront utilis√©es pour pr√©fixe √† chaque fois que n√©cessaire, par exemple pour d√©finir des variables d'nevironnement, des noms de conteneurs, etc.

### Gestion des variables racines
La variable `DSDC_DIR` identifie le r√©pertoire racine du projet. Elle est identifi√© √† l'aide d'un fichier marqueur .dsdc_project_root
**Ne jamais supprimer ce fichier.**

### Fichiers de configuration config.yaml:
Il permet de d√©finir la configuration de l'environnement. Ce fichier ne doit pas √™tre synchronis√© sur git.

Il est donc inscrit dans le .gitignore et un template est dynamiquement cr√©√© lors de l'ex√©cution du script prepare.sh

### Fichiers de credentials .secret:
Il permet de d√©finir tous les credentials de l'environnement. Ce fichier ne doit absolument pas √™tre synchronis√© sur git.

Il est donc inscrit dans le .gitignore et un template est dynamiquement cr√©√© lors de l'ex√©cution du script prepare.sh

## 3. Description d√©taill√©e

### 3.1 Structure du projet

Le projet suit une architecture modulaire bien organis√©e, con√ßue pour assurer la **s√©paration des responsabilit√©s** entre le code m√©tier, les donn√©es, les scripts d‚Äôautomatisation, les tests, et les services.

```
.
‚îú‚îÄ‚îÄ config.yaml                  # Fichier de configuration principal (non versionn√© par d√©faut)
‚îú‚îÄ‚îÄ data/                        # R√©pertoire contenant les donn√©es du projet
‚îÇ   ‚îú‚îÄ‚îÄ raw/                     # Donn√©es brutes en attente de traitement
‚îÇ   ‚îú‚îÄ‚îÄ processed/               # Donn√©es pr√©trait√©es, pr√™tes √† √™tre utilis√©es
‚îÇ   ‚îú‚îÄ‚îÄ rejected/              ¬† # Donn√©es ayant √©chou√© le pr√©traitement ou validation
‚îÇ   ‚îî‚îÄ‚îÄ to_ingest/             ¬†# Donn√©es en attente d'importation
‚îú‚îÄ‚îÄ docs/                        # Documentation technique et visuelle (diagrammes, stack, etc.)
‚îú‚îÄ‚îÄ dsdc/                        # Package principal Python (modules m√©tiers)
‚îÇ   ‚îú‚îÄ‚îÄ data/                    # Chargement, validation, exportation de donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ db/                      # Interfaces et requ√™tes SQL
‚îÇ   ‚îú‚îÄ‚îÄ models/                  # Scripts d'entra√Ænement et d'inf√©rence
‚îÇ   ‚îú‚îÄ‚îÄ scripts/                 # Scripts d'orchestration pour Airflow
‚îÇ   ‚îî‚îÄ‚îÄ utils/                   # Fonctions utilitaires diverses
‚îú‚îÄ‚îÄ logs/                        # Logs g√©n√©r√©s par les DAGs Airflow
‚îú‚îÄ‚îÄ models/                      # R√©pertoire contenant les artefacts ML (MLflow, checkpoints)
‚îú‚îÄ‚îÄ scripts/                     # Scripts shell pour g√©rer le projet (install, start, stop, etc.)
‚îú‚îÄ‚îÄ services/                    # Services conteneuris√©s (Airflow, MLflow, Streamlit, etc.)
‚îú‚îÄ‚îÄ tests/                       # Tests unitaires et d‚Äôint√©gration
‚îú‚îÄ‚îÄ tmp/                         # Fichiers temporaires
‚îú‚îÄ‚îÄ todo/                        # Notes de travail ou t√¢ches √† faire
‚îú‚îÄ‚îÄ pyproject.toml               # D√©pendances et configuration Python
‚îî‚îÄ‚îÄ README.md                    # Documentation principale
```

Cette structure permet un d√©ploiement en local ou sur un serveur distant de mani√®re fluide via Docker Compose, tout en gardant un haut niveau de maintenabilit√©.

---

### 3.2 Stack technique

Le projet s'appuie sur un ensemble de technologies modernes et bien int√©gr√©es, couvrant le cycle de vie complet d‚Äôun projet de machine learning en production (MLOps).

#### Orchestration et automatisation

- **Apache Airflow** : orchestrateur de workflows, utilis√© pour g√©rer les pipelines de traitement, entra√Ænement et d√©ploiement.
- **Docker Compose** : permet de d√©finir et g√©rer tous les services n√©cessaires au projet dans un environnement isol√©.

#### Backend et traitement

- **PostgreSQL** : base de donn√©es relationnelle utilis√©e pour stocker les documents, m√©tadonn√©es, textes extraits, embeddings, etc.
- **FastAPI** : framework web l√©ger pour exposer les endpoints de pr√©diction, d'authentification, ou de services internes.
- **CLIP (OpenAI)** : mod√®le de vision/texte utilis√© pour g√©n√©rer des embeddings de documents.

#### Machine Learning

- **MLflow** : gestion des exp√©riences, suivi des mod√®les, gestion des artefacts.
- **PyTorch** : utilis√© pour l‚Äôentra√Ænement des mod√®les (via `dsdc.models`).
- **Embeddings** : des vecteurs de dimension 1024 sont g√©n√©r√©s pour les images et les textes, √† l‚Äôaide de CLIP, et stock√©s en base.

#### Frontend & UX

- **Streamlit** : application interactive pour tester les pr√©dictions du mod√®le en temps r√©el.

#### Monitoring

- **Prometheus + Grafana** : infrastructure de monitoring des services, de la base de donn√©es et des performances.

---

### 3.3 Base de donn√©es `dsdc`

La base de donn√©es centrale du projet s'appelle `dsdc`. Elle joue un r√¥le critique dans la tra√ßabilit√© de bout en bout d‚Äôun document : de son importation brute jusqu‚Äô√† l‚Äôinf√©rence du mod√®le.

> üí° Le script SQL de cr√©ation des tables se trouve ici :  
> `services/postgres/init_dbs/init_dsdc.sql`

#### 3.3.1 Vue d'ensemble

La base est structur√©e de mani√®re **relationnelle** autour de la table `original_documents`, qui sert de point d‚Äôentr√©e pour chaque document.

L‚Äôensemble du pipeline de traitement s'appuie ensuite sur des relations claires entre les diff√©rentes entit√©s d√©riv√©es du document :

- **Images extraites**
- **Textes bruts et trait√©s**
- **Embeddings**
- **Labels**

---

#### 3.3.2 Description des tables

- **original_documents**  
  Contient les documents bruts import√©s (PDF, PNG, etc.), leur chemin d'acc√®s, et des m√©tadonn√©es comme la date d'import.

- **labels**  
  Permet d‚Äôassocier des annotations humaines ou automatiques √† un document. Chaque label est li√© √† un document via `document_id`.

- **processed_images**  
  Repr√©sente les images d√©riv√©es des documents (ex : pages d‚Äôun PDF converties en PNG). Chaque image est trac√©e avec le nom du processeur utilis√© et la date de traitement.

- **raw_texts**  
  Contient le texte brut extrait d‚Äôun document. Le type d‚Äôextraction (OCR, parser PDF, etc.) est enregistr√©.

- **processed_texts**  
  Texte ayant subi un pr√©traitement (nettoyage, normalisation, etc.) √† partir des `raw_texts`.

- **embeddings**  
  Cette table est cl√© pour les t√¢ches de machine learning. Elle contient les vecteurs num√©riques (embeddings) associ√©s √† une image ou un texte trait√©. Chaque entr√©e est associ√©e :
  - √† un `processed_image_id` (embedding d‚Äôimage),
  - ou √† un `processed_text_id` (embedding de texte),
  avec la version du mod√®le CLIP utilis√©e.

---

#### 3.3.3 Indexation et performance

Des indexes sont d√©finis sur les colonnes les plus couramment utilis√©es pour les jointures et les requ√™tes, afin de garantir des performances √©lev√©es dans les pipelines et les API.

Par exemple :

- `labels.document_id`  
- `processed_images.document_id`  
- `raw_texts.document_id`  
- `processed_texts.raw_text_id`  
- `embeddings.processed_text_id`  
- `embeddings.processed_image_id`

---

#### 3.3.4 Flux de donn√©es dans la base

Voici un exemple de parcours d‚Äôun document :

1. Un fichier est plac√© dans `data/to_ingest/`, puis import√© par un DAG Airflow.
2. Il est enregistr√© dans `original_documents`.
3. Un extracteur g√©n√®re :
   - des images (enregistr√©es dans `processed_images`)
   - du texte brut (`raw_texts`)
4. Ce texte est nettoy√© et transform√© (`processed_texts`).
5. Des embeddings sont calcul√©s (image, texte ou les deux) et stock√©s dans `embeddings`.
6. Un annotateur (humain ou automatique) fournit des `labels`.

---

#### 3.3.5 Pourquoi une telle structure ?

Cette organisation permet :

- une **tra√ßabilit√© compl√®te** de chaque √©tape du pipeline,
- une **modularit√©** dans les traitements (possibilit√© de changer de processeur sans casser les relations),
- une **int√©gration facile avec les mod√®les ML**, en extrayant √† tout moment un batch propre et structur√© pour l‚Äôentra√Ænement ou la pr√©diction.

---

#### 3.3.6 Int√©gration avec MLflow

Les embeddings, labels, et autres m√©tadonn√©es peuvent √™tre utilis√©s comme entr√©es dans un pipeline MLflow pour :

- lancer des exp√©riences,
- tester diff√©rents mod√®les ou pr√©traitements,
- suivre les performances de mani√®re reproductible.

---

### 3.4 S√©curit√© et authentification

- Un service **`auth`** bas√© sur FastAPI permet de g√©rer les tokens JWT.
- Chaque utilisateur (humain ou service) peut ainsi s‚Äôauthentifier avant d‚Äôacc√©der √† l‚ÄôAPI de pr√©diction.
- La cl√© secr√®te JWT est configurable via des variables d‚Äôenvironnement.

---

### 3.5 D√©ploiement

L‚Äôensemble du projet est con√ßu pour fonctionner avec :

```bash
./scripts/start.sh
```

Cela lance tous les services via `docker-compose`, monte les volumes n√©cessaires, initialise la base de donn√©es si besoin, et met en route Airflow.

Pour tout red√©ploiement ou nettoyage :

```bash
./scripts/hard_reset.sh
```

Ce script supprime les conteneurs, volumes temporaires et images Docker locales li√©es au projet.

---

### 3.6 Observabilit√©

Un pipeline complet de monitoring est inclus :

- **Prometheus** scrappe les m√©triques des services et des bases PostgreSQL.
- **Grafana** fournit des dashboards en temps r√©el.
- Des exporters d√©di√©s permettent de suivre l‚Äôusage des bases `dsdc`, `airflow`, et `mlflow`.

---

### 3.7 Environnement de dev

L‚Äôenvironnement Python est d√©fini dans `pyproject.toml`.  
Un environnement virtuel peut √™tre activ√© avec :

```bash
python -m venv .venv
source .venv/bin/activate
```

Il est recommand√© d‚Äôutiliser `uv
